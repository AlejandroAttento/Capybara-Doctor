{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from huggingface_hub import hf_hub_download\n",
    "import transformers\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace=\"the_gale_encyclopedia_of_medicine\" # Needs to be updated, each document should have a different namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config Manager set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigManager:\n",
    "    def __init__(self, json_config_path: str):\n",
    "        self.json_config_path = json_config_path\n",
    "        self.json_config = None\n",
    "\n",
    "        self._load_config_json()\n",
    "\n",
    "    def _load_config_json(self):\n",
    "        try:\n",
    "            with open(self.json_config_path, \"r\") as file_obj:\n",
    "                self.json_config = json.load(file_obj)\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"Configuration file not found: {self.json_config_path}\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Error decoding JSON file: {e}\")\n",
    "\n",
    "    def get_config(self, keys: str | list, default=None):\n",
    "        if isinstance(keys, str):\n",
    "            keys = [keys]\n",
    "\n",
    "        data = self.json_config\n",
    "        for key in keys:\n",
    "            if isinstance(data, dict):\n",
    "                data = data.get(key, default)\n",
    "            else:\n",
    "                return default\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_manager = ConfigManager(\"config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load environment varibales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(config_manager.get_config(\"llm_model_directory\"), config_manager.get_config(\"llm_model_name\"))\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    model_path = hf_hub_download(\n",
    "        repo_id=config_manager.get_config(\"llm_model_repository_name\"), \n",
    "        filename=config_manager.get_config(\"llm_model_name\"),\n",
    "        local_dir=config_manager.get_config(\"llm_model_directory\"),\n",
    "        token=os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process RAG documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(\n",
    "    config_manager.get_config(\"data_directory\"),\n",
    "    glob=\"*.pdf\",\n",
    "    loader_cls=PyPDFLoader,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.21s/it]\n"
     ]
    }
   ],
   "source": [
    "extracted_data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=config_manager.get_config([\"text_split\", \"chunk_size\"]), \n",
    "    chunk_overlap=config_manager.get_config([\"text_split\", \"chunk_overlap\"])\n",
    ")\n",
    "\n",
    "data_chunks = text_splitter.split_documents(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of created data chunks: 5961\n"
     ]
    }
   ],
   "source": [
    "print(f\"Amount of created data chunks: {len(data_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load documents into VectorDB (Pinecone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=config_manager.get_config(\"embedding_model_name\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Pinecone connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(config_manager.get_config(\"pinecone_index_name\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate duplicated vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace_exists = index.query(vector=embeddings.embed_query(data_chunks[0].page_content), top_k=1, namespace=namespace).get(\"matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating duplicated data chunks: 100%|██████████| 5961/5961 [00:51<00:00, 115.49it/s]\n"
     ]
    }
   ],
   "source": [
    "if namespace_exists:\n",
    "    def check_duplication(chunk):\n",
    "        duplicated = index.query(vector=embeddings.embed_query(chunk.page_content), top_k=1, namespace=namespace).get(\"matches\")[0].get(\"score\") >= 0.99\n",
    "        return chunk.page_content if not duplicated else None\n",
    "\n",
    "    deduplicated_data_chunks = list()\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(check_duplication, chunk): chunk for chunk in data_chunks}\n",
    "\n",
    "        for future in tqdm(as_completed(futures), total=len(data_chunks), desc=\"Validating duplicated data chunks\"):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                deduplicated_data_chunks.append(result)\n",
    "else:\n",
    "    deduplicated_data_chunks = [chunk.page_content for chunk in data_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 not duplicated vectors will be added.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(deduplicated_data_chunks)} not duplicated vectors will be added.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_id(content):\n",
    "    return hashlib.md5(content.encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chunks_ids = [generate_id(chunk) for chunk in deduplicated_data_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = vector_store.add_texts(texts=deduplicated_data_chunks, ids=data_chunks_ids, namespace=namespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't have enough information to answer them please answer \"I don't have enough information to answer that question.\"\n",
    "Only return the helpful answer below and nothing else.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context: \n",
    "{context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    template=prompt, \n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain_type_kwargs={\"prompt\": prompt_template}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = CTransformers(\n",
    "    model=model_path,\n",
    "    model_type=\"llama\",\n",
    "    config={\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"temperature\": 0.8\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa=RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever(search_kwargs={\"namespace\": namespace}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = qa.invoke({\"query\": \"What is Cancer?\"}, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast year old lady with information about\n",
      "I don'\n",
      "The most common types of\n",
      "You have enough information provided\n",
      "Breast chance (For patientswith highlitely cancer cells in a)\n",
      "I can you are many of HP\n",
      "You seem to be foundational Health care providers provide an infection\n",
      "The most people with\n",
      "The most common.\n",
      "To diagnosis of information is\n",
      "Breastasis,\n",
      "Breast year, I don'\n",
      "The\n",
      "The\n",
      "The two pieces of breast cancerous mammuncontrolled by the\n",
      "I have enough information provided\n",
      "Breast\n",
      "BreastrophyesYou don’ The HIV, although some forms or click heres can provide additional information about.\n",
      "Yes,\n",
      "I don'\n",
      "I don'\n",
      "I don'\n",
      "I don'\n",
      "The type=\n",
      "I don'\n",
      "I don'\n",
      "Breast cancer cells are there are cancer originates are cancer can give themic information that helpfull breast cancer treatment for answer.\n",
      "I have enough information to answer:\n",
      "The\n",
      "The\n",
      "The\n",
      "The\n",
      "The most common types of course,\n",
      "I don'\n",
      "I don'\n",
      "I don'\n",
      "To perform a\n",
      "The patient with more... The type \n",
      "Breast cancer cells in the pro-A biops belowHelpful answer:\n",
      "I have enough information to answer:\n",
      "We do not helpful answer_ ____________.\n",
      "The\n",
      "The\n",
      "The\n",
      "The best response  I need to\n",
      "Yes,\n",
      "I don'\n",
      "I can you will be sure!\n",
      "Breast cancer cells or\n",
      "To answer- Cancerous symptoms to answer.\n",
      "You have enough information on\n",
      "I don'\n",
      "I don'\n",
      "Breastasis of the patient information\n",
      "Breast cancer.\n",
      "The type \n",
      "I don'\n",
      "I don'\n",
      "I can you need more information\n",
      "Breast year\n",
      "Breast cancer cells in a)\n",
      "I don'I have enough information\n",
      "The\n",
      "I don'\n",
      "I don'\n",
      "I don'\n",
      "I don'\n",
      "I don'\n",
      "I don'\n",
      "I don'\n",
      "Breast.\n",
      "Breastasis.\n",
      "Breast\n",
      "Breast\n",
      "Breast year.\n",
      "I can you will help@Sorry,\n",
      "I have enough information to answer:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I don'\n",
      "I don'\n",
      "I can provide details ons and treatment of\n",
      "Breast.\n",
      "Thank you doctors to\n",
      "You have enough\n"
     ]
    }
   ],
   "source": [
    "print(response.get(\"result\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
